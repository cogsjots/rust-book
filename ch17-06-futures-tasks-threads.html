<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Futures, Tasks, and Threads - The Rust Programming Language</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="ferris.css">
        <link rel="stylesheet" href="theme/2018-edition.css">
        <link rel="stylesheet" href="theme/semantic-notes.css">
        <link rel="stylesheet" href="theme/listing.css">

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">

                <div id="content" class="content">
                    <main>
                        <h2 id="futures-tasks-and-threads"><a class="header" href="#futures-tasks-and-threads">Futures, Tasks, and Threads</a></h2>
<p>As we saw in the previous chapter, threads provide one approach to concurrency.
We’ve seen another approach to concurrency in this chapter, using async with
futures and streams. You might be wondering why you would choose one or the
other. The answer is: it depends! And in many cases, the choice isn’t threads
<em>or</em> async but rather threads <em>and</em> async.</p>
<p>Many operating systems have supplied threading-based concurrency models for
decades now, and many programming languages have support for them as a result.
However, they are not without their tradeoffs. On many operating systems, they
use a fair bit of memory for each thread, and they come with some overhead for
starting up and shutting down. Threads are also only an option when your
operating system and hardware support them! Unlike mainstream desktop and mobile
computers, some embedded systems don’t have an OS at all, so they also don’t
have threads!</p>
<p>The async model provides a different—and ultimately complementary—set of
tradeoffs. In the async model, concurrent operations don’t require their own
threads. Instead, they can run on tasks, as when we used <code>trpl::spawn_task</code> to
kick off work from a synchronous function throughout the streams section. A task
is similar to a thread, but instead of being managed by the operating system,
it’s managed by library-level code: the runtime.</p>
<p>In the previous section, we saw that we could build a <code>Stream</code> by using an async
channel and spawning an async task which we could call from synchronous code. We
could do the exact same thing with a thread! In Listing 17-40, we used
<code>trpl::spawn_task</code> and <code>trpl::sleep</code>. In Listing 17-41, we replace those with
the <code>thread::spawn</code> and <code>thread::sleep</code> APIs from the standard library in the
<code>get_intervals</code> function.</p>
<figure class="listing">
<span class="file-name">Filename: src/main.rs</span>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate trpl; // required for mdbook test
</span><span class="boring">
</span><span class="boring">use std::{pin::pin, thread, time::Duration};
</span><span class="boring">
</span><span class="boring">use trpl::{ReceiverStream, Stream, StreamExt};
</span><span class="boring">
</span><span class="boring">fn main() {
</span><span class="boring">    trpl::run(async {
</span><span class="boring">        let messages = get_messages().timeout(Duration::from_millis(200));
</span><span class="boring">        let intervals = get_intervals()
</span><span class="boring">            .map(|count| format!("Interval #{count}"))
</span><span class="boring">            .throttle(Duration::from_millis(500))
</span><span class="boring">            .timeout(Duration::from_secs(10));
</span><span class="boring">        let merged = messages.merge(intervals).take(20);
</span><span class="boring">        let mut stream = pin!(merged);
</span><span class="boring">
</span><span class="boring">        while let Some(result) = stream.next().await {
</span><span class="boring">            match result {
</span><span class="boring">                Ok(item) =&gt; println!("{item}"),
</span><span class="boring">                Err(reason) =&gt; eprintln!("Problem: {reason:?}"),
</span><span class="boring">            }
</span><span class="boring">        }
</span><span class="boring">    });
</span><span class="boring">}
</span><span class="boring">
</span><span class="boring">fn get_messages() -&gt; impl Stream&lt;Item = String&gt; {
</span><span class="boring">    let (tx, rx) = trpl::channel();
</span><span class="boring">
</span><span class="boring">    trpl::spawn_task(async move {
</span><span class="boring">        let messages = ["a", "b", "c", "d", "e", "f", "g", "h", "i", "j"];
</span><span class="boring">
</span><span class="boring">        for (index, message) in messages.into_iter().enumerate() {
</span><span class="boring">            let time_to_sleep = if index % 2 == 0 { 100 } else { 300 };
</span><span class="boring">            trpl::sleep(Duration::from_millis(time_to_sleep)).await;
</span><span class="boring">
</span><span class="boring">            if let Err(send_error) = tx.send(format!("Message: '{message}'")) {
</span><span class="boring">                eprintln!("Cannot send message '{message}': {send_error}");
</span><span class="boring">                break;
</span><span class="boring">            }
</span><span class="boring">        }
</span><span class="boring">    });
</span><span class="boring">
</span><span class="boring">    ReceiverStream::new(rx)
</span><span class="boring">}
</span><span class="boring">
</span>fn get_intervals() -&gt; impl Stream&lt;Item = u32&gt; {
    let (tx, rx) = trpl::channel();

    // This is *not* `trpl::spawn` but `std::thread::spawn`!
    thread::spawn(move || {
        let mut count = 0;
        loop {
            // Likewise, this is *not* `trpl::sleep` but `std::thread::sleep`!
            thread::sleep(Duration::from_millis(1));
            count += 1;

            if let Err(send_error) = tx.send(count) {
                eprintln!("Could not send interval {count}: {send_error}");
                break;
            };
        }
    });

    ReceiverStream::new(rx)
}</code></pre></pre>
<figcaption>Listing 17-41: Using the <code>std::thread</code> APIs instead of the async <code>trpl</code> APIs for the <code>get_intervals</code> function</figcaption>
</figure>
<p>If you run this, the output is identical. And notice how little changes here
from the perspective of the calling code! What’s more, even though one of our
functions spawned an async task on the runtime and the other spawned an
OS thread, the resulting streams were unaffected by the differences.</p>
<p>Despite the similarities, these two approaches behave very differently, although
we might have a hard time measuring it in this very simple example. We could
spawn millions of async tasks on any modern personal computer. If we tried to do
that with threads, we would literally run out of memory!</p>
<p>However, there’s a reason these APIs are so similar. Threads act as a boundary
for sets of synchronous operations; concurrency is possible <em>between</em> threads.
Tasks act as a boundary for sets of <em>asynchronous</em> operations; concurrency is
possible both <em>between</em> and <em>within</em> tasks, because a task can switch between
futures in its body. Finally, futures are Rust’s most granular unit of
concurrency, and each future may represent a tree of other futures. The
runtime—specifically, its executor—manages tasks, and tasks manage futures. In
that regard, tasks are similar to lightweight, runtime-managed threads with
added capabilities that come from being managed by a runtime instead of by the
operating system.</p>
<p>This doesn’t mean that async tasks are always better than threads, any more than
that threads are always better than tasks.</p>
<p>Concurrency with threads is in some ways a simpler programming model than
concurrency with <code>async</code>. That can be a strength or a weakness. Threads are
somewhat “fire and forget,” they have no native equivalent to a future, so they
simply run to completion, without interruption except by the operating system
itself. That is, they have no built-in support for <em>intra-task concurrency</em> the
way futures do. Threads in Rust also have no mechanisms for cancellation—a
subject we haven’t covered in depth in this chapter, but which is implicit in
the fact that whenever we ended a future, its state got cleaned up correctly.</p>
<p>These limitations also make threads harder to compose than futures. It’s much
more difficult, for example, to use threads to build helpers such as the
<code>timeout</code> we built in <a href="ch17-03-more-futures.html#building-our-own-async-abstractions">“Building Our Own Async Abstractions”</a>
or the <code>throttle</code> method we used with streams in <a href="ch17-04-streams.html#composing-streams">“Composing Streams”</a>.
The fact that futures are richer data structures means they can be composed
together more naturally, as we have seen.</p>
<p>Tasks then give <em>additional</em> control over futures, allowing you to choose where
and how to group the futures. And it turns out that threads and tasks often
work very well together, because tasks can (at least in some runtimes) be moved
around between threads. We haven’t mentioned it up until now, but under the
hood the <code>Runtime</code> we have been using, including the <code>spawn_blocking</code> and
<code>spawn_task</code> functions, is multithreaded by default! Many runtimes use an
approach called <em>work stealing</em> to transparently move tasks around between
threads based on the current utilization of the threads, with the aim of
improving the overall performance of the system. To build that actually requires
threads <em>and</em> tasks, and therefore futures.</p>
<p>As a default way of thinking about which to use when:</p>
<ul>
<li>If the work is <em>very parallelizable</em>, such as processing a bunch of data where
each part can be processed separately, threads are a better choice.</li>
<li>If the work is <em>very concurrent</em>, such as handling messages from a bunch of
different sources which may come in a different intervals or different rates,
async is a better choice.</li>
</ul>
<p>And if you need some mix of parallelism and concurrency, you don’t have to
choose between threads and async. You can use them together freely, letting each
one serve the part it is best at. For example, Listing 17-42 shows a fairly
common example of this kind of mix in real-world Rust code.</p>
<figure class="listing">
<span class="file-name">Filename: src/main.rs</span>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">extern crate trpl; // for mdbook test
</span><span class="boring">
</span>use std::{thread, time::Duration};

fn main() {
    let (tx, mut rx) = trpl::channel();

    thread::spawn(move || {
        for i in 1..11 {
            tx.send(i).unwrap();
            thread::sleep(Duration::from_secs(1));
        }
    });

    trpl::run(async {
        while let Some(message) = rx.recv().await {
            println!("{message}");
        }
    });
}</code></pre></pre>
<figcaption>Listing 17-42: Sending messages with blocking code in a thread and awaiting the messages in an async block</figcaption>
</figure>
<p>We begin by creating an async channel. Then we spawn a thread which takes
ownership of the sender side of the channel. Within the thread, we send the
numbers 1 through 10, and sleep for a second in between each. Finally, we run a
future created with an async block passed to <code>trpl::run</code> just as we have
throughout the chapter. In that future, we await those messages, just as in
the other message-passing examples we have seen.</p>
<p>To return to the examples we opened the chapter with: you could imagine running
a set of video encoding tasks using a dedicated thread, because video encoding
is compute bound, but notifying the UI that those operations are done with an
async channel. Examples of this kind of mix abound!</p>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>This isn’t the last you’ll see of concurrency in this book: the project in
Chapter 21 will use the concepts in this chapter in a more realistic situation
than the smaller examples discussed here—and compare more directly what it looks
like to solve these kinds of problems with threading vs. with tasks and futures.</p>
<p>Whether with threads, with futures and tasks, or with the combination of them
all, Rust gives you the tools you need to write safe, fast, concurrent
code—whether for a high-throughput web server or an embedded operating system.</p>
<p>Next, we’ll talk about idiomatic ways to model problems and structure solutions
as your Rust programs get bigger. In addition, we’ll discuss how Rust’s idioms
relate to those you might be familiar with from object-oriented programming.</p>

                    </main>

                </div>
            </div>


        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="ferris.js"></script>


    </div>
    </body>
</html>
